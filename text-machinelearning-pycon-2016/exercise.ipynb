{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Exercise: Yelp reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This exercise uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.csv`** contains the dataset. It is stored in the repository (in the **`data`** directory), so there is no need to download anything from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text.\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`yelp.csv`** into a pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_df=pd.read_csv(\"data/yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    object\n",
       "date           object\n",
       "review_id      object\n",
       "stars           int64\n",
       "text           object\n",
       "type           object\n",
       "user_id        object\n",
       "cool            int64\n",
       "useful          int64\n",
       "funny           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'business_id', u'date', u'review_id', u'stars', u'text', u'type',\n",
       "       u'user_id', u'cool', u'useful', u'funny'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "- **Hint:** [How do I apply multiple filter criteria to a pandas DataFrame?](http://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb#9.-How-do-I-apply-multiple-filter-criteria-to-a-pandas-DataFrame%3F-%28video%29) explains how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_df_1_5=yelp_df[(yelp_df['stars']==1) | (yelp_df['stars']==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df_1_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "- **Hint:** Keep in mind that X should be a pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4086,), (4086,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=yelp_df_1_5[\"text\"]\n",
    "y=yelp_df_1_5[\"stars\"]\n",
    "print X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2860,) (1226,) (2860,) (1226,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.3)\n",
    "print X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "Count=CountVectorizer()\n",
    "X_train_dtm=Count.fit_transform(X_train)\n",
    "X_test_dtm=Count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(X_train_dtm,y_train)\n",
    "y_pred=nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.911092985318\n",
      "[[149  84]\n",
      " [ 25 968]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print \"Accuracy=\",accuracy_score(y_test,y_pred)\n",
    "print confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print y_test.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_counts=y_train.value_counts()\n",
    "most_freq_class=class_counts.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_dummy=pd.Series(np.array([most_freq_class]*y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.809951060359\n",
      "[[  0 233]\n",
      " [  0 993]]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy=\",accuracy_score(y_test,y_dummy)\n",
    "print confusion_matrix(y_test,y_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains the definitions of \"false positives\" and \"false negatives\".\n",
    "- **Hint:** Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_fp=X_test[y_pred>y_test]\n",
    "X_test_fn=X_test[y_pred<y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've passed by prestige nails in walmart 100s of times but never really thought of having a pedicure there (even though they are always busy!) As I stared at my feet, long overdue for a pedicure, I thought it was about time to try them...since walmart rarely let's me down why should the nail salon inside?\n",
      "\n",
      "To my surprise I got a wonderful pedicure or $23 not too bad this day in age...my to mention it was just as good as going to the more upscale salon just across the street! \n",
      "\n",
      "I'm glad to be the first to review them they deserve it! Now if only they did facials at walmart and hair I'd be set!\n",
      "We happened upon this location when meeting a friend for dinner.  When I showed up there was a line of about 20 people ahead of me.  i asked them to put me in first available and they said 15-20min and then 45min for a booth.\n",
      "\n",
      "Ok, I'll wait.\n",
      "\n",
      "Our friends showed up and my girlfriend had asked if there was a spot at the bar we could sit in the mean time.  We were there for about 10min already.  That's when she said to us. \"Your table inside is ready\"  she walked us right there and we were sat.  WOW!  that was quick!\n",
      "\n",
      "We ordered drinks and food.  I got these jerk chicken wings for an appetizer and holy cow, they were delicious.  For my main dish I ordered a garlic noodle dish.  It definitely hit the spot.  My only beef would be that it was hard to talk with so many people inside.  I wont let that affect the rating though.\n",
      "\n",
      "Awesome place!\n",
      "This store has the most pleasant employees of any Forever 21 I have ever been to. The girls are always smiling and they take the time to esquire if you need help. The other day, I went in and an employee spent over 10 minutes helping me locate a particular skirt my sister wanted for Christmas.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print X_test_fn[X_test_fn.index[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "Calculate which 10 tokens are the most predictive of **5-star reviews**, and which 10 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "- **Hint:** Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the `feature_count_` and `class_count_` attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Starryness_df=pd.DataFrame({\"Word\":Count.get_feature_names(),\"1 star appearances\":nb.feature_count_[0],\"5 star appearances\":nb.feature_count_[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Starryness_df=Starryness_df.set_index('Word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 star appearances</th>\n",
       "      <th>5 star appearances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03342</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0buxoc0crqjpvkezo3bqog</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0l</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000x</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100s</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100th</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10am</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinburgergeist</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinfandel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcar</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziploc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipper</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zippers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziti</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoners</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zones</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoyo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucca</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuccini</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuchinni</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumba</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zupa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zupas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuzu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>école</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ém</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        1 star appearances  5 star appearances\n",
       "Word                                                          \n",
       "00                                    27.0                36.0\n",
       "000                                    4.0                 5.0\n",
       "00a                                    1.0                 0.0\n",
       "00am                                   3.0                 1.0\n",
       "00pm                                   1.0                 6.0\n",
       "01                                     0.0                 1.0\n",
       "02                                     1.0                 1.0\n",
       "03                                     1.0                 0.0\n",
       "03342                                  1.0                 0.0\n",
       "04                                     0.0                 1.0\n",
       "05                                     0.0                 2.0\n",
       "06                                     0.0                 1.0\n",
       "07                                     2.0                 5.0\n",
       "09                                     0.0                 2.0\n",
       "0buxoc0crqjpvkezo3bqog                 2.0                 0.0\n",
       "0l                                     1.0                 0.0\n",
       "10                                    66.0               130.0\n",
       "100                                   18.0                34.0\n",
       "1000                                   1.0                 4.0\n",
       "1000x                                  1.0                 0.0\n",
       "1001                                   0.0                 1.0\n",
       "100s                                   1.0                 0.0\n",
       "100th                                  0.0                 2.0\n",
       "101                                    5.0                 6.0\n",
       "1030                                   1.0                 1.0\n",
       "105                                    0.0                 2.0\n",
       "1070                                   1.0                 0.0\n",
       "108                                    0.0                 1.0\n",
       "109                                    0.0                 1.0\n",
       "10am                                   0.0                 3.0\n",
       "...                                    ...                 ...\n",
       "zinburgergeist                         0.0                 1.0\n",
       "zinc                                   0.0                 3.0\n",
       "zinfandel                              0.0                 2.0\n",
       "zing                                   0.0                 1.0\n",
       "zip                                    0.0                 2.0\n",
       "zipcar                                 0.0                 1.0\n",
       "ziploc                                 0.0                 1.0\n",
       "zipper                                 0.0                 1.0\n",
       "zippers                                0.0                 1.0\n",
       "ziti                                   0.0                 2.0\n",
       "zoe                                    0.0                 4.0\n",
       "zombies                                0.0                 1.0\n",
       "zone                                   1.0                 2.0\n",
       "zoners                                 0.0                 1.0\n",
       "zones                                  0.0                 1.0\n",
       "zoning                                 0.0                 1.0\n",
       "zoo                                    0.0                 7.0\n",
       "zoom                                   1.0                 0.0\n",
       "zoyo                                   0.0                 1.0\n",
       "zucca                                  0.0                 1.0\n",
       "zucchini                               1.0                 9.0\n",
       "zuccini                                0.0                 1.0\n",
       "zuchinni                               0.0                 1.0\n",
       "zumba                                  0.0                 3.0\n",
       "zupa                                   0.0                 1.0\n",
       "zupas                                  0.0                 1.0\n",
       "zuzu                                   0.0                 1.0\n",
       "zzed                                   0.0                 1.0\n",
       "école                                  0.0                 1.0\n",
       "ém                                     0.0                 1.0\n",
       "\n",
       "[16218 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Starryness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Starryness_df[\"1 starryness\"]=(nb.feature_count_[0]+1)/nb.class_count_[0]\n",
    "Starryness_df[\"5 starryness\"]=(nb.feature_count_[1]+1)/nb.class_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Starryness_df[\"Differentiability\"]=Starryness_df[\"5 starryness\"]/Starryness_df[\"1 starryness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 star appearances</th>\n",
       "      <th>5 star appearances</th>\n",
       "      <th>1 starryness</th>\n",
       "      <th>5 starryness</th>\n",
       "      <th>Differentiability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.078498</td>\n",
       "      <td>40.505119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>2.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.099403</td>\n",
       "      <td>17.097270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fabulous</th>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.031997</td>\n",
       "      <td>16.510239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.026024</td>\n",
       "      <td>13.428328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.123720</td>\n",
       "      <td>12.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>5.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.119027</td>\n",
       "      <td>10.236348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.018771</td>\n",
       "      <td>9.686007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>9.025597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bianco</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>8.805461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>8.585324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dentist</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>7.924915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chili</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>7.924915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavors</th>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>7.851536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>7.704778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resort</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>7.704778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deals</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>7.484642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coconut</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>7.264505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>12.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.180034</td>\n",
       "      <td>7.145970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waffles</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>7.044369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creamy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>7.044369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>6.824232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasty</th>\n",
       "      <td>4.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>6.780205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>5.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.077645</td>\n",
       "      <td>6.677474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delish</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>6.604096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy</th>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.037969</td>\n",
       "      <td>6.530717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>6.383959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pet</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>6.383959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>6.163823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>6.163823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pancakes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>6.163823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nozzle</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.036689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thier</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.036689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incompetent</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.036689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airways</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledged</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pischke</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processed</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screwed</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inedible</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innova</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nibbles</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mediocre</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.030019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rude</th>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.029634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.029352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuse</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ants</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratuity</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fedex</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible</th>\n",
       "      <td>71.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boca</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silverware</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.024460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudely</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.024460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unprofessional</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.024460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.024460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blah</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.020012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bouncers</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.020012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavorless</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.018345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuck</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1 star appearances  5 star appearances  1 starryness  \\\n",
       "Word                                                                   \n",
       "fantastic                      0.0               183.0      0.001938   \n",
       "perfect                        2.0               232.0      0.005814   \n",
       "fabulous                       0.0                74.0      0.001938   \n",
       "yum                            0.0                60.0      0.001938   \n",
       "favorite                       4.0               289.0      0.009690   \n",
       "awesome                        5.0               278.0      0.011628   \n",
       "fruit                          0.0                43.0      0.001938   \n",
       "pasty                          0.0                40.0      0.001938   \n",
       "bianco                         0.0                39.0      0.001938   \n",
       "gem                            0.0                38.0      0.001938   \n",
       "dentist                        0.0                35.0      0.001938   \n",
       "chili                          0.0                35.0      0.001938   \n",
       "flavors                        2.0               106.0      0.005814   \n",
       "mozzarella                     0.0                34.0      0.001938   \n",
       "resort                         0.0                34.0      0.001938   \n",
       "deals                          0.0                33.0      0.001938   \n",
       "coconut                        0.0                32.0      0.001938   \n",
       "amazing                       12.0               421.0      0.025194   \n",
       "waffles                        0.0                31.0      0.001938   \n",
       "creamy                         0.0                31.0      0.001938   \n",
       "superb                         0.0                30.0      0.001938   \n",
       "tasty                          4.0               153.0      0.009690   \n",
       "wonderful                      5.0               181.0      0.011628   \n",
       "delish                         0.0                29.0      0.001938   \n",
       "yummy                          2.0                88.0      0.005814   \n",
       "mesa                           0.0                28.0      0.001938   \n",
       "pet                            0.0                28.0      0.001938   \n",
       "organic                        0.0                27.0      0.001938   \n",
       "creative                       0.0                27.0      0.001938   \n",
       "pancakes                       0.0                27.0      0.001938   \n",
       "...                            ...                 ...           ...   \n",
       "nozzle                         5.0                 0.0      0.011628   \n",
       "thier                          5.0                 0.0      0.011628   \n",
       "incompetent                    5.0                 0.0      0.011628   \n",
       "airways                        6.0                 0.0      0.013566   \n",
       "acknowledged                   6.0                 0.0      0.013566   \n",
       "pischke                        6.0                 0.0      0.013566   \n",
       "processed                      6.0                 0.0      0.013566   \n",
       "screwed                        6.0                 0.0      0.013566   \n",
       "inedible                       6.0                 0.0      0.013566   \n",
       "innova                         6.0                 0.0      0.013566   \n",
       "nibbles                        6.0                 0.0      0.013566   \n",
       "mediocre                      21.0                 2.0      0.042636   \n",
       "rude                          51.0                 6.0      0.100775   \n",
       "worst                         59.0                 7.0      0.116279   \n",
       "unacceptable                   7.0                 0.0      0.015504   \n",
       "fuse                           7.0                 0.0      0.015504   \n",
       "ants                           7.0                 0.0      0.015504   \n",
       "gratuity                       7.0                 0.0      0.015504   \n",
       "fedex                          7.0                 0.0      0.015504   \n",
       "horrible                      71.0                 8.0      0.139535   \n",
       "boca                           7.0                 0.0      0.015504   \n",
       "silverware                     8.0                 0.0      0.017442   \n",
       "rudely                         8.0                 0.0      0.017442   \n",
       "unprofessional                 8.0                 0.0      0.017442   \n",
       "disgusting                    17.0                 1.0      0.034884   \n",
       "blah                          10.0                 0.0      0.021318   \n",
       "bouncers                      10.0                 0.0      0.021318   \n",
       "flavorless                    11.0                 0.0      0.023256   \n",
       "ugh                           12.0                 0.0      0.025194   \n",
       "yuck                          12.0                 0.0      0.025194   \n",
       "\n",
       "                5 starryness  Differentiability  \n",
       "Word                                             \n",
       "fantastic           0.078498          40.505119  \n",
       "perfect             0.099403          17.097270  \n",
       "fabulous            0.031997          16.510239  \n",
       "yum                 0.026024          13.428328  \n",
       "favorite            0.123720          12.767918  \n",
       "awesome             0.119027          10.236348  \n",
       "fruit               0.018771           9.686007  \n",
       "pasty               0.017491           9.025597  \n",
       "bianco              0.017065           8.805461  \n",
       "gem                 0.016638           8.585324  \n",
       "dentist             0.015358           7.924915  \n",
       "chili               0.015358           7.924915  \n",
       "flavors             0.045648           7.851536  \n",
       "mozzarella          0.014932           7.704778  \n",
       "resort              0.014932           7.704778  \n",
       "deals               0.014505           7.484642  \n",
       "coconut             0.014078           7.264505  \n",
       "amazing             0.180034           7.145970  \n",
       "waffles             0.013652           7.044369  \n",
       "creamy              0.013652           7.044369  \n",
       "superb              0.013225           6.824232  \n",
       "tasty               0.065700           6.780205  \n",
       "wonderful           0.077645           6.677474  \n",
       "delish              0.012799           6.604096  \n",
       "yummy               0.037969           6.530717  \n",
       "mesa                0.012372           6.383959  \n",
       "pet                 0.012372           6.383959  \n",
       "organic             0.011945           6.163823  \n",
       "creative            0.011945           6.163823  \n",
       "pancakes            0.011945           6.163823  \n",
       "...                      ...                ...  \n",
       "nozzle              0.000427           0.036689  \n",
       "thier               0.000427           0.036689  \n",
       "incompetent         0.000427           0.036689  \n",
       "airways             0.000427           0.031448  \n",
       "acknowledged        0.000427           0.031448  \n",
       "pischke             0.000427           0.031448  \n",
       "processed           0.000427           0.031448  \n",
       "screwed             0.000427           0.031448  \n",
       "inedible            0.000427           0.031448  \n",
       "innova              0.000427           0.031448  \n",
       "nibbles             0.000427           0.031448  \n",
       "mediocre            0.001280           0.030019  \n",
       "rude                0.002986           0.029634  \n",
       "worst               0.003413           0.029352  \n",
       "unacceptable        0.000427           0.027517  \n",
       "fuse                0.000427           0.027517  \n",
       "ants                0.000427           0.027517  \n",
       "gratuity            0.000427           0.027517  \n",
       "fedex               0.000427           0.027517  \n",
       "horrible            0.003840           0.027517  \n",
       "boca                0.000427           0.027517  \n",
       "silverware          0.000427           0.024460  \n",
       "rudely              0.000427           0.024460  \n",
       "unprofessional      0.000427           0.024460  \n",
       "disgusting          0.000853           0.024460  \n",
       "blah                0.000427           0.020012  \n",
       "bouncers            0.000427           0.020012  \n",
       "flavorless          0.000427           0.018345  \n",
       "ugh                 0.000427           0.016934  \n",
       "yuck                0.000427           0.016934  \n",
       "\n",
       "[16218 rows x 5 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Starryness_df.sort_values(\"Differentiability\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "- Print the confusion matrix, and comment on the results. (This [Stack Overflow answer](http://stackoverflow.com/a/30748053/1636598) explains how to read a multi-class confusion matrix.)\n",
    "- Print the [classification report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), and comment on the results. If you are unfamiliar with the terminology it uses, research the terms, and then try to figure out how to calculate these metrics manually from the confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xf=yelp_df[\"text\"]\n",
    "yf=yelp_df[\"stars\"]\n",
    "Xf_train,Xf_test,yf_train,yf_test=train_test_split(Xf,yf,random_state=42,test_size=0.3)\n",
    "Countf=CountVectorizer()\n",
    "Xf_train_dtm=Countf.fit_transform(Xf_train)\n",
    "Xf_test_dtm=Countf.transform(Xf_test)\n",
    "nbf=MultinomialNB()\n",
    "nbf.fit(Xf_train_dtm,yf_train)\n",
    "yf_pred=nbf.predict(Xf_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.494\n",
      "[[ 59  23  17  84  35]\n",
      " [ 18  24  42 152  29]\n",
      " [  3   7  49 333  50]\n",
      " [  7   4  11 805 260]\n",
      " [  3   0   5 435 545]]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy=\",accuracy_score(yf_test,yf_pred)\n",
    "print confusion_matrix(yf_test,yf_pred,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.27      0.38       218\n",
      "          2       0.41      0.09      0.15       265\n",
      "          3       0.40      0.11      0.17       442\n",
      "          4       0.44      0.74      0.56      1087\n",
      "          5       0.59      0.55      0.57       988\n",
      "\n",
      "avg / total       0.50      0.49      0.46      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(yf_test,yf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.291\n",
      "[[ 17  25  28  72  76]\n",
      " [ 14  26  37  91  97]\n",
      " [ 35  37  67 165 138]\n",
      " [ 86 109 140 389 363]\n",
      " [ 63  77 130 344 374]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dumb=DummyClassifier()\n",
    "dumb.fit(Xf_train_dtm,yf_train)\n",
    "yf_dummy=dumb.predict(Xf_test_dtm)\n",
    "print accuracy_score(yf_test,yf_dummy)\n",
    "print confusion_matrix(yf_test,yf_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.329333333333\n"
     ]
    }
   ],
   "source": [
    "print np.sum([ 63,77,130,344,374])/3000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out SVC and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.459666666667\n",
      "[[ 80  48  27  29  34]\n",
      " [ 44  75  65  48  33]\n",
      " [ 18  45 131 164  84]\n",
      " [ 18  48 129 504 388]\n",
      " [ 12  12  49 326 589]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      0.37      0.41       218\n",
      "          2       0.33      0.28      0.30       265\n",
      "          3       0.33      0.30      0.31       442\n",
      "          4       0.47      0.46      0.47      1087\n",
      "          5       0.52      0.60      0.56       988\n",
      "\n",
      "avg / total       0.45      0.46      0.46      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC()\n",
    "svc.fit(Xf_train_dtm,yf_train)\n",
    "ysvc_pred=svc.predict(Xf_test_dtm)\n",
    "print \"Accuracy=\",accuracy_score(yf_test,ysvc_pred)\n",
    "print confusion_matrix(yf_test,ysvc_pred)\n",
    "print classification_report(yf_test,ysvc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.406\n",
      "[[ 27  15  37  74  65]\n",
      " [ 26  18  40 128  53]\n",
      " [  8  16  75 249  94]\n",
      " [ 17  22  85 637 326]\n",
      " [  8  13  41 465 461]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.12      0.18       218\n",
      "          2       0.21      0.07      0.10       265\n",
      "          3       0.27      0.17      0.21       442\n",
      "          4       0.41      0.59      0.48      1087\n",
      "          5       0.46      0.47      0.46       988\n",
      "\n",
      "avg / total       0.38      0.41      0.38      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as Rf\n",
    "rf=Rf()\n",
    "rf.fit(Xf_train_dtm,yf_train)\n",
    "yrf_pred=rf.predict(Xf_test_dtm)\n",
    "print \"Accuracy=\",accuracy_score(yf_test,yrf_pred)\n",
    "print confusion_matrix(yf_test,yrf_pred)\n",
    "print classification_report(yf_test,yrf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out GridSearchCV with LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xc_train,Xc_cv,yc_train,tc_cv=train_test_split(X_train,y_train,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe=Pipeline([('vect', CountVectorizer()),('svc',LinearSVC())])\n",
    "params={'vect__ngram_range':[(1,1),(1,2),(2,2)],'svc__C':[0.01,0.1,1.0,10.0,100.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=0.01, score=0.500857 -   2.0s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=0.01, score=0.500857 -   2.0s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=0.01, score=0.491424 -   2.0s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=0.01, score=0.505141 -   4.8s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=0.01, score=0.520566 -   4.8s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=0.01, score=0.487136 -   4.8s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=0.01, score=0.465724 -   2.9s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=0.01, score=0.482434 -   3.0s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.01 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=0.01, score=0.457547 -   3.0s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=0.1, score=0.473865 -   2.4s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=0.1, score=0.486718 -   2.5s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=0.1, score=0.463551 -   2.3s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=0.1, score=0.493145 -   4.7s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=0.1, score=0.509426 -   5.3s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=0.1, score=0.469125 -   5.0s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(2, 2), svc__C=0.1, score=0.454156 -   3.5s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(2, 2), svc__C=0.1, score=0.478578 -   3.5s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=0.1 ............................\n",
      "[CV] ... vect__ngram_range=(2, 2), svc__C=0.1, score=0.452830 -   3.3s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=1.0, score=0.442159 -   3.4s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=1.0, score=0.458440 -   3.2s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 1), svc__C=1.0, score=0.440823 -   3.5s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=1.0, score=0.484576 -   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=1.0, score=0.498286 -   5.5s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(1, 2), svc__C=1.0, score=0.460978 -   5.2s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=1.0 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... vect__ngram_range=(2, 2), svc__C=1.0, score=0.449871 -   3.4s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(2, 2), svc__C=1.0, score=0.455013 -   3.5s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=1.0 ............................\n",
      "[CV] ... vect__ngram_range=(2, 2), svc__C=1.0, score=0.446827 -   3.5s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=10.0, score=0.424165 -   3.6s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=10.0, score=0.447301 -   3.7s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 1), svc__C=10.0, score=0.438679 -   3.6s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=10.0, score=0.467866 -   6.6s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=10.0, score=0.490574 -   6.3s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(1, 2), svc__C=10.0, score=0.464837 -   5.8s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=10.0, score=0.439589 -   4.7s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=10.0, score=0.451585 -   5.2s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=10.0 ...........................\n",
      "[CV] .. vect__ngram_range=(2, 2), svc__C=10.0, score=0.447684 -   4.9s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 1), svc__C=100.0, score=0.418166 -   3.8s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 1), svc__C=100.0, score=0.431448 -   3.8s\n",
      "[CV] vect__ngram_range=(1, 1), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 1), svc__C=100.0, score=0.437393 -   3.7s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 2), svc__C=100.0, score=0.449015 -  10.5s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 2), svc__C=100.0, score=0.484147 -  14.3s\n",
      "[CV] vect__ngram_range=(1, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(1, 2), svc__C=100.0, score=0.445111 -   8.4s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(2, 2), svc__C=100.0, score=0.431448 -  11.9s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(2, 2), svc__C=100.0, score=0.449443 -  13.2s\n",
      "[CV] vect__ngram_range=(2, 2), svc__C=100.0 ..........................\n",
      "[CV] . vect__ngram_range=(2, 2), svc__C=100.0, score=0.440823 -  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], 'svc__C': [0.01, 0.1, 1.0, 10.0, 100.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=4)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier=GridSearchCV(pipe,params,verbose=4,cv=3)\n",
    "best_classifier.fit(Xf_train,yf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.49771, std: 0.00445, params: {'vect__ngram_range': (1, 1), 'svc__C': 0.01},\n",
       " mean: 0.50429, std: 0.01366, params: {'vect__ngram_range': (1, 2), 'svc__C': 0.01},\n",
       " mean: 0.46857, std: 0.01036, params: {'vect__ngram_range': (2, 2), 'svc__C': 0.01},\n",
       " mean: 0.47471, std: 0.00948, params: {'vect__ngram_range': (1, 1), 'svc__C': 0.1},\n",
       " mean: 0.49057, std: 0.01655, params: {'vect__ngram_range': (1, 2), 'svc__C': 0.1},\n",
       " mean: 0.46186, std: 0.01184, params: {'vect__ngram_range': (2, 2), 'svc__C': 0.1},\n",
       " mean: 0.44714, std: 0.00801, params: {'vect__ngram_range': (1, 1), 'svc__C': 1.0},\n",
       " mean: 0.48129, std: 0.01541, params: {'vect__ngram_range': (1, 2), 'svc__C': 1.0},\n",
       " mean: 0.45057, std: 0.00338, params: {'vect__ngram_range': (2, 2), 'svc__C': 1.0},\n",
       " mean: 0.43671, std: 0.00955, params: {'vect__ngram_range': (1, 1), 'svc__C': 10.0},\n",
       " mean: 0.47443, std: 0.01149, params: {'vect__ngram_range': (1, 2), 'svc__C': 10.0},\n",
       " mean: 0.44629, std: 0.00500, params: {'vect__ngram_range': (2, 2), 'svc__C': 10.0},\n",
       " mean: 0.42900, std: 0.00804, params: {'vect__ngram_range': (1, 1), 'svc__C': 100.0},\n",
       " mean: 0.45943, std: 0.01755, params: {'vect__ngram_range': (1, 2), 'svc__C': 100.0},\n",
       " mean: 0.44057, std: 0.00735, params: {'vect__ngram_range': (2, 2), 'svc__C': 100.0}]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.530666666667\n",
      "[[ 99  34  21  30  34]\n",
      " [ 49  70  63  48  35]\n",
      " [ 13  24 127 193  85]\n",
      " [  6  19  79 587 396]\n",
      " [  3   3  18 255 709]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.45      0.51       218\n",
      "          2       0.47      0.26      0.34       265\n",
      "          3       0.41      0.29      0.34       442\n",
      "          4       0.53      0.54      0.53      1087\n",
      "          5       0.56      0.72      0.63       988\n",
      "\n",
      "avg / total       0.52      0.53      0.52      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_pred=best_classifier.predict(Xf_test)\n",
    "print \"Accuracy=\",accuracy_score(yf_test,best_pred)\n",
    "print confusion_matrix(yf_test,best_pred)\n",
    "print classification_report(yf_test,best_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe2=Pipeline([('vect', CountVectorizer(ngram_range=(1,2))),('rf',Rf())])\n",
    "params={'rf__max_depth':[5,6,7,8,None],'rf__n_estimators':[5,10,15,20,25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] rf__max_depth=5, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=5, rf__n_estimators=5, score=0.376642 -   3.5s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=5, rf__n_estimators=5, score=0.382504 -   3.4s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=10, score=0.389492 -   3.4s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=10, score=0.385649 -   3.4s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=15, score=0.383210 -   3.5s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=15, score=0.401658 -   3.5s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=20, score=0.392347 -   3.5s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=20, score=0.397084 -   3.5s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=25, score=0.392347 -   3.6s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=5, rf__n_estimators=25, score=0.416238 -   3.6s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=6, rf__n_estimators=5, score=0.369503 -   3.6s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=6, rf__n_estimators=5, score=0.379360 -   3.6s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=10, score=0.382924 -   4.0s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=10, score=0.385935 -   4.0s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=15, score=0.392633 -   4.6s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=15, score=0.402230 -   4.0s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=20, score=0.400057 -   4.1s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=20, score=0.399085 -   4.1s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=25, score=0.406339 -   4.0s\n",
      "[CV] rf__max_depth=6, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=6, rf__n_estimators=25, score=0.392796 -   3.8s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=7, rf__n_estimators=5, score=0.375500 -   3.7s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=7, rf__n_estimators=5, score=0.383648 -   3.6s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=10, score=0.380640 -   4.4s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=10, score=0.385649 -   4.3s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=15 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... rf__max_depth=7, rf__n_estimators=15, score=0.381496 -   4.0s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=15, score=0.384505 -   3.8s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=20, score=0.391776 -   3.8s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=20, score=0.407376 -   3.8s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=25, score=0.405197 -   4.1s\n",
      "[CV] rf__max_depth=7, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=7, rf__n_estimators=25, score=0.400800 -   4.1s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=8, rf__n_estimators=5, score=0.380925 -   3.7s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=5 .............................\n",
      "[CV] .... rf__max_depth=8, rf__n_estimators=5, score=0.369640 -   3.8s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=10, score=0.391491 -   3.7s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=10 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=10, score=0.393082 -   3.7s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=15, score=0.386636 -   3.7s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=15 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=15, score=0.393654 -   3.7s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=20, score=0.402627 -   3.8s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=20 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=20, score=0.413379 -   3.9s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=25, score=0.394061 -   4.0s\n",
      "[CV] rf__max_depth=8, rf__n_estimators=25 ............................\n",
      "[CV] ... rf__max_depth=8, rf__n_estimators=25, score=0.406232 -   3.8s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=5 ..........................\n",
      "[CV] . rf__max_depth=None, rf__n_estimators=5, score=0.371788 -   4.7s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=5 ..........................\n",
      "[CV] . rf__max_depth=None, rf__n_estimators=5, score=0.385935 -   4.6s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=10 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=10, score=0.394346 -   5.7s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=10 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=10, score=0.411378 -   5.7s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=15 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=15, score=0.402913 -   6.6s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=15 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=15, score=0.420526 -   6.7s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=20 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=20, score=0.413192 -   8.5s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=20 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=20, score=0.416238 -   8.0s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=25 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=25, score=0.413192 -   8.8s\n",
      "[CV] rf__max_depth=None, rf__n_estimators=25 .........................\n",
      "[CV]  rf__max_depth=None, rf__n_estimators=25, score=0.432819 -   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        st...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'rf__max_depth': [5, 6, 7, 8, None], 'rf__n_estimators': [5, 10, 15, 20, 25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=4)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier2=GridSearchCV(pipe2,params,verbose=4,cv=2)\n",
    "best_classifier2.fit(Xf_train,yf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.453\n",
      "[[ 13   3  15 105  82]\n",
      " [  4   4  22 172  63]\n",
      " [  1   1  19 331  90]\n",
      " [  0   1  14 685 387]\n",
      " [  0   2   6 342 638]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.06      0.11       218\n",
      "          2       0.36      0.02      0.03       265\n",
      "          3       0.25      0.04      0.07       442\n",
      "          4       0.42      0.63      0.50      1087\n",
      "          5       0.51      0.65      0.57       988\n",
      "\n",
      "avg / total       0.44      0.45      0.39      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_pred2=best_classifier2.predict(Xf_test)\n",
    "print \"Accuracy=\",accuracy_score(yf_test,best_pred2)\n",
    "print confusion_matrix(yf_test,best_pred2)\n",
    "print classification_report(yf_test,best_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.37957, std: 0.00293, params: {'rf__max_depth': 5, 'rf__n_estimators': 5},\n",
       " mean: 0.38757, std: 0.00192, params: {'rf__max_depth': 5, 'rf__n_estimators': 10},\n",
       " mean: 0.39243, std: 0.00922, params: {'rf__max_depth': 5, 'rf__n_estimators': 15},\n",
       " mean: 0.39471, std: 0.00237, params: {'rf__max_depth': 5, 'rf__n_estimators': 20},\n",
       " mean: 0.40429, std: 0.01195, params: {'rf__max_depth': 5, 'rf__n_estimators': 25},\n",
       " mean: 0.37443, std: 0.00493, params: {'rf__max_depth': 6, 'rf__n_estimators': 5},\n",
       " mean: 0.38443, std: 0.00151, params: {'rf__max_depth': 6, 'rf__n_estimators': 10},\n",
       " mean: 0.39743, std: 0.00480, params: {'rf__max_depth': 6, 'rf__n_estimators': 15},\n",
       " mean: 0.39957, std: 0.00049, params: {'rf__max_depth': 6, 'rf__n_estimators': 20},\n",
       " mean: 0.39957, std: 0.00677, params: {'rf__max_depth': 6, 'rf__n_estimators': 25},\n",
       " mean: 0.37957, std: 0.00407, params: {'rf__max_depth': 7, 'rf__n_estimators': 5},\n",
       " mean: 0.38314, std: 0.00250, params: {'rf__max_depth': 7, 'rf__n_estimators': 10},\n",
       " mean: 0.38300, std: 0.00150, params: {'rf__max_depth': 7, 'rf__n_estimators': 15},\n",
       " mean: 0.39957, std: 0.00780, params: {'rf__max_depth': 7, 'rf__n_estimators': 20},\n",
       " mean: 0.40300, std: 0.00220, params: {'rf__max_depth': 7, 'rf__n_estimators': 25},\n",
       " mean: 0.37529, std: 0.00564, params: {'rf__max_depth': 8, 'rf__n_estimators': 5},\n",
       " mean: 0.39229, std: 0.00080, params: {'rf__max_depth': 8, 'rf__n_estimators': 10},\n",
       " mean: 0.39014, std: 0.00351, params: {'rf__max_depth': 8, 'rf__n_estimators': 15},\n",
       " mean: 0.40800, std: 0.00538, params: {'rf__max_depth': 8, 'rf__n_estimators': 20},\n",
       " mean: 0.40014, std: 0.00609, params: {'rf__max_depth': 8, 'rf__n_estimators': 25},\n",
       " mean: 0.37886, std: 0.00707, params: {'rf__max_depth': None, 'rf__n_estimators': 5},\n",
       " mean: 0.40286, std: 0.00852, params: {'rf__max_depth': None, 'rf__n_estimators': 10},\n",
       " mean: 0.41171, std: 0.00881, params: {'rf__max_depth': None, 'rf__n_estimators': 15},\n",
       " mean: 0.41471, std: 0.00152, params: {'rf__max_depth': None, 'rf__n_estimators': 20},\n",
       " mean: 0.42300, std: 0.00981, params: {'rf__max_depth': None, 'rf__n_estimators': 25}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
