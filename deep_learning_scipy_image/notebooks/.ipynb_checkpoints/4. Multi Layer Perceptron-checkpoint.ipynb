{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Model for MNIST\n",
    "\n",
    "Deep Learning models can take quite a bit of time to run, particularly if GPU isn't used. In the interest of time, we will sample 1000 observations that are 6 and 1000 observations that aren't 6. We will build a model using that and see how it performs on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the training and testing data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path_to_data)\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Seed for reproducibilty\n",
    "np.random.seed(1338)\n",
    "\n",
    "#test data\n",
    "\n",
    "X_test = X_test.copy()\n",
    "Y = y_test.copy()\n",
    "#Converting the output to binary classification(Six=1,Not Six=0)\n",
    "Y_test = Y == 6\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "#Selecting the 5918 examples where the output is 6\n",
    "X_six = X_train[y_train == 6].copy()\n",
    "Y_six = y_train[y_train == 6].copy()\n",
    "#Selecting the examples where the output is not 6\n",
    "X_not_six = X_train[y_train != 6].copy()\n",
    "Y_not_six = y_train[y_train != 6].copy()\n",
    "\n",
    "#Selecting 6000 random examples from the data that contains only the data where the output is not 6\n",
    "random_rows = np.random.randint(0,X_six.shape[0],6000)\n",
    "X_not_six = X_not_six[random_rows]\n",
    "Y_not_six = Y_not_six[random_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Appending the data with output as 6 and data with output as not six\n",
    "X_train = np.append(X_six,X_not_six)\n",
    "#Reshaping the appended data to appropraite form\n",
    "X_train = X_train.reshape(X_six.shape[0] + X_not_six.shape[0], 784)\n",
    "#Appending the labels and converting the labels to binary classification(Six=1,Not Six=0)\n",
    "Y_labels = np.append(Y_six,Y_not_six)\n",
    "Y_train = Y_labels == 6 \n",
    "Y_train = Y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11918, 784) (11918,) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_labels.shape, Y_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the classes to its binary categorical form\n",
    "nb_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the multi layer perceptron\n",
    "batch_size = 128\n",
    "nb_epoch = 2\n",
    "#Activation Functions\n",
    "activations = \"sigmoid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 0s - loss: 0.5869 - acc: 0.8091 - val_loss: 0.4224 - val_acc: 0.9664\n",
      "Test score: 0.422354313231\n",
      "Test accuracy: 0.9664\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1338)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Increase epochs to 10 and observe the modeling performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add one more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.6809 - acc: 0.5805 - val_loss: 0.9486 - val_acc: 0.0958\n",
      "Test score: 0.948558405685\n",
      "Test accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1338)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization: Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.1594 - acc: 0.9403 - val_loss: 0.0623 - val_acc: 0.9771\n",
      "Test score: 0.0622818493906\n",
      "Test accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1338)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Run the above for 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more dropout layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.2710 - acc: 0.8856 - val_loss: 0.1018 - val_acc: 0.9631\n",
      "Test score: 0.101808118149\n",
      "Test accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1338)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1338)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(512, W_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the multi layer perceptron\n",
    "batch_size = 128\n",
    "nb_epoch = 1\n",
    "#Activation Functions\n",
    "activations = ['relu','tanh','sigmoid']\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for constructing the multi layer perceptron\n",
    "def build_model(activation):\n",
    "    \n",
    "    np.random.seed(1338)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVATION relu \n",
      "\n",
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.4153 - acc: 0.8727 - val_loss: 0.2514 - val_acc: 0.9495\n",
      "Test score: 0.25144048841\n",
      "Test accuracy: 0.9495\n",
      "1 loop, best of 1: 5.1 s per loop\n",
      "\n",
      "\n",
      "ACTIVATION tanh \n",
      "\n",
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.2812 - acc: 0.9093 - val_loss: 0.1669 - val_acc: 0.9529\n",
      "Test score: 0.166866254115\n",
      "Test accuracy: 0.9529\n",
      "1 loop, best of 1: 3.27 s per loop\n",
      "\n",
      "\n",
      "ACTIVATION sigmoid \n",
      "\n",
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 1s - loss: 0.7185 - acc: 0.5130 - val_loss: 0.7161 - val_acc: 0.1525\n",
      "Test score: 0.716095627594\n",
      "Test accuracy: 0.1525\n",
      "1 loop, best of 1: 3.36 s per loop\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in activations:\n",
    "    print('ACTIVATION',i,'\\n')\n",
    "    %timeit -n1 -r1 build_model(i)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "1. Change the above to 15 epochs and observe the test accuracy\n",
    "\n",
    "2. Modify SGD parameters and observe the test accuracy\n",
    "\n",
    "3. Change the optimizer and observe test accuracy. For learning purpose, let's use 5 epochs\n",
    "\n",
    "4. The weights initialization method has a significant impact on how the network learns. We will not go much into this in this workshop - but look into how and where the initialization is done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Loss Functions in `keras`\n",
    "http://keras.io/objectives/\n",
    "\n",
    "### Available Optimizers in `keras`\n",
    "http://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
