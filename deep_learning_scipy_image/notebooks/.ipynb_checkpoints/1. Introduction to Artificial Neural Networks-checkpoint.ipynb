{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks\n",
    "\n",
    "**Goal** : This notebook explains the building blocks of a neural network model. \n",
    "\n",
    "**Data** : Data is taken from `sklearn`'s `make_moon` dataset. There are two features and and the target is a categorical variable (0/1). The aim is to devise an algorithm that correctly classifies the datapoints. \n",
    "\n",
    "**Aproach**: We will build the neural networks from first principles. We will create a very simple model and understand how it works. We will also be implementing backpropagation algorithm. Please note that this code is not optimized. This is for instructive purpose - for us to understand how ANN works. Libraries like `theano` have highly optimized code.\n",
    "\n",
    "(*This notebook is inspired from [this](https://github.com/dennybritz/nn-from-scratch) brilliant notebook*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(123)\n",
    "# Display plots inline \n",
    "%matplotlib inline\n",
    "# Define plot's default figure size\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the datasets\n",
    "\n",
    "train = pd.read_csv(\"../data/intro_to_ann.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = np.array(train.ix[:,0:2]), np.array(train.ix[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's plot the dataset and see how it is\n",
    "plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.BuGn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start building our neural network's building blocks. \n",
    "\n",
    "This process will eventually result in our own Neural Networks class\n",
    "\n",
    "### Function to generate a random number, given two numbers\n",
    "\n",
    "**Where will it be used?**: When we initialize the neural networks, the weights have to be randomly assigned. Remember?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate a random number where:  a <= rand < b\n",
    "def rand(a, b):\n",
    "    return (b-a)*random.random() + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a matrix \n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    return np.zeros([I,J])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our activation function. Let's use sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our sigmoid function\n",
    "def sigmoid(x):\n",
    "    #return math.tanh(x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative of our activation function. We need this when we run the backpropagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# derivative of our sigmoid function, in terms of the output (i.e. y)\n",
    "def dsigmoid(y):\n",
    "    return y - y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our neural networks class\n",
    "\n",
    "When we first create a neural networks architecture, we need to know the number of inputs, number of hidden layers and number of outputs.\n",
    "\n",
    "The weights have to be randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1 # +1 for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "        \n",
    "        # create weights\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "        \n",
    "        # set them to random vaules\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.2, 0.2)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-2.0, 2.0)\n",
    "\n",
    "        # last change in weights for momentum   \n",
    "        self.ci = makeMatrix(self.ni, self.nh)\n",
    "        self.co = makeMatrix(self.nh, self.no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Backpropagation Algorithm\n",
    "\n",
    "After the forward-pass, we need to compute the error for the output. The error is backpropagated to the layers before it. The weights are adjusted, based on how much they contributed to the prediction error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backPropagate(self, targets, N, M):\n",
    "        \n",
    "    if len(targets) != self.no:\n",
    "        print(targets)\n",
    "        raise ValueError('wrong number of target values')\n",
    "\n",
    "    # calculate error terms for output\n",
    "    #output_deltas = [0.0] * self.no\n",
    "    output_deltas = np.zeros(self.no)\n",
    "    for k in range(self.no):\n",
    "        error = targets[k]-self.ao[k]\n",
    "        output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "    # calculate error terms for hidden\n",
    "        \n",
    "    #hidden_deltas = [0.0] * self.nh\n",
    "    hidden_deltas = np.zeros(self.nh)\n",
    "    for j in range(self.nh):\n",
    "        error = 0.0\n",
    "        for k in range(self.no):\n",
    "            error = error + output_deltas[k]*self.wo[j][k]\n",
    "        hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "    # update output weights\n",
    "    for j in range(self.nh):\n",
    "        for k in range(self.no):\n",
    "            change = output_deltas[k]*self.ah[j]\n",
    "            self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "            self.co[j][k] = change\n",
    "            #print N*change, M*self.co[j][k]\n",
    "\n",
    "    # update input weights\n",
    "    for i in range(self.ni):\n",
    "        for j in range(self.nh):\n",
    "            change = hidden_deltas[j]*self.ai[i]\n",
    "            self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "            self.ci[i][j] = change\n",
    "\n",
    "    # calculate error\n",
    "    error = 0.0\n",
    "    for k in range(len(targets)):\n",
    "        error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, the full Neural Networks class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1 # +1 for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "        \n",
    "        # create weights\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "        \n",
    "        # set them to random vaules\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.2, 0.2)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-2.0, 2.0)\n",
    "\n",
    "        # last change in weights for momentum   \n",
    "        self.ci = makeMatrix(self.ni, self.nh)\n",
    "        self.co = makeMatrix(self.nh, self.no)\n",
    "        \n",
    "\n",
    "    def backPropagate(self, targets, N, M):\n",
    "        \n",
    "        if len(targets) != self.no:\n",
    "            print(targets)\n",
    "            raise ValueError('wrong number of target values')\n",
    "\n",
    "        # calculate error terms for output\n",
    "        #output_deltas = [0.0] * self.no\n",
    "        output_deltas = np.zeros(self.no)\n",
    "        for k in range(self.no):\n",
    "            error = targets[k]-self.ao[k]\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        # calculate error terms for hidden\n",
    "        \n",
    "        #hidden_deltas = [0.0] * self.nh\n",
    "        hidden_deltas = np.zeros(self.nh)\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "                #print N*change, M*self.co[j][k]\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "        return error\n",
    "\n",
    "\n",
    "    def test(self, patterns):\n",
    "        self.predict = np.empty([len(patterns), self.no])\n",
    "        for i, p in enumerate(patterns):\n",
    "            self.predict[i] = self.activate(p)\n",
    "            #self.predict[i] = self.activate(p[0])\n",
    "\n",
    "    def weights(self):\n",
    "        print('Input weights:')\n",
    "        for i in range(self.ni):\n",
    "            print(self.wi[i])\n",
    "        \n",
    "        print('Output weights:')\n",
    "        for j in range(self.nh):\n",
    "            print(self.wo[j])\n",
    "            \n",
    "    def activate(self, inputs):\n",
    "        \n",
    "        if len(inputs) != self.ni-1:\n",
    "            print(inputs)\n",
    "            raise ValueError('wrong number of inputs')\n",
    "\n",
    "        # input activations\n",
    "        for i in range(self.ni-1):\n",
    "            #self.ai[i] = sigmoid(inputs[i])\n",
    "            self.ai[i] = inputs[i]\n",
    "            \n",
    "        \n",
    "\n",
    "        # hidden activations\n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "           \n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "\n",
    "        \n",
    "        return self.ao[:]\n",
    "    \n",
    "\n",
    "    def train(self, patterns, iterations=1000, N=0.5, M=0.1):\n",
    "        # N: learning rate\n",
    "        # M: momentum factor\n",
    "        patterns = list(patterns)\n",
    "        for i in range(iterations):\n",
    "            error1 = 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.activate(inputs)\n",
    "                error1 = error1 + self.backPropagate([targets], N, M)\n",
    "            if i % 5 == 0:\n",
    "                print('error in interation %d : %-.5f' % (i,error1))\n",
    "            print('Final training error: %-.5f' % error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a network with two inputs, one hidden, and one output nodes\n",
    "\n",
    "n = NN(2, 1, 1)\n",
    "\n",
    "%timeit -n 1 -r 1 n.train(zip(X,y), iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on training dataset and measuring in-sample accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 n.test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data=np.array([y, np.ravel(n.predict)]).T, columns=[\"actual\", \"prediction\"])\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(prediction.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize and observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "# This generates the contour plot to show the decision boundary visually\n",
    "def plot_decision_boundary(nn_model):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    nn_model.test(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = nn_model.predict\n",
    "    Z[Z>=0.5] = 1\n",
    "    Z[Z<0.5] = 0\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=40,  c=y, cmap=plt.cm.BuGn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(n)\n",
    "plt.title(\"Our initial model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Create Neural networks with 10 hidden layers on the above code. What's the impact on accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = NN(2, 10, 1)\n",
    "%timeit -n 1 -r 1 n.train(zip(X,y), iterations=2)\n",
    "plot_decision_boundary(n)\n",
    "plt.title(\"Our next model with 10 hidden units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Train the neural networks by increasing the epochs. What's the impact on accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = NN(2, 10, 1)\n",
    "%timeit -n 1 -r 1 n.train(zip(X,y), iterations=10)\n",
    "plot_decision_boundary(n)\n",
    "plt.title(\"Our model with 10 hidden units and 10 iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
